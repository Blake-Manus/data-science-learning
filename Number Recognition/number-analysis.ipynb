{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################################\n",
    "### Creator: Ricky Blake Manus\n",
    "### Objective: Analysis of MNIST Dataset to accurately classify and predict the value of \n",
    "### hand written digits ranging from 0-9 from a 28x28 Pixel source image\n",
    "###\n",
    "### MNIST Dataset & Testing Data obtained from Kaggle.com\n",
    "### Data and Competition can be found at https://www.kaggle.com/c/digit-recognizer/overview\n",
    "####################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Notebook Options and Optimizations\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import CSV Training and Testing Data, noting the layout and columns of the dataset\n",
    "test_data = pd.read_csv('data-sets/test.csv')\n",
    "train_data = pd.read_csv('data-sets/train.csv')\n",
    "\n",
    "#Remove the labels and move them to a separate numpy array\n",
    "labels = np.array(train_data.pop('label'))\n",
    "\n",
    "train_data.head(5)\n",
    "\n",
    "### The resulting dataframe contains 785 columns, and 42000 Rows\n",
    "### 1 label column which contains the represented digit, moved to a numpy array\n",
    "### 784 Pixel columns that represent the grayscale value of that pixel from 0-255 (inclusive)\n",
    "### Each image is represented by 28x28 pixel image (784 Pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###The First the I wish to try is to create a heatmap of the data \n",
    "###    so that I can have a greater visualization of it.\n",
    "###############################################################\n",
    "\n",
    "#Grab the sum of the values\n",
    "sum_data = train_data.sum(axis=0)\n",
    "\n",
    "#Pass the sum data to heat_data as a numpy array,\n",
    "#Parse the data into the proper 28x28 pixel format\n",
    "heat_data = sum_data.to_numpy()\n",
    "heat_data = heat_data.reshape(28, 28) \n",
    "\n",
    "ax = sns.heatmap(heat_data, cmap='mako')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use LabelEncoder first, to properly format labels as OneHotEncoder needs a 2d Array\n",
    "#Then use OneHotEncoder to format the labels again\n",
    "labels = LabelEncoder().fit_transform(labels)[:, None]\n",
    "labels = OneHotEncoder().fit_transform(labels).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Convert data to a scaled numpy array, and\n",
    "###   reshape the data into a 2d 28x28 image\n",
    "train_data = StandardScaler().fit_transform(np.float32(train_data.values))\n",
    "train_data = train_data.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tr_data (33600, 784) |||| v_data (8400, 784) |||| train_data (42000, 784) |||| test_data (28000, 784)\n"
     ]
    }
   ],
   "source": [
    "###Split the data into training and validation data with an 80-20 split\n",
    "tr_data, v_data = train_data[:-8400], train_data[-8400:]\n",
    "tr_labels, v_labels = labels[:-8400], labels[-8400:]\n",
    "print('tr_data ' + str(tr_data.shape) + ' |||| v_data ' + str(v_data.shape) + \n",
    "      ' |||| train_data ' + str(train_data.shape) + ' |||| test_data ' + str(test_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
